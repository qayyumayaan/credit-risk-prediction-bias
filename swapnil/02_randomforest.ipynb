{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99abf03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec22b70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.dropna(inplace=True)\n",
    "# df.sample(20)\n",
    "# df.info()\n",
    "# df.columns\n",
    "\n",
    "# print(df.NAME_TYPE_SUITE.unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e4565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load train & test\n",
    "train = pd.read_csv('../data/application_train.csv')\n",
    "test  = pd.read_csv('../data/application_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea36a22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 122 columns.\n",
      "There are 67 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Missing Values",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "% of Total Values",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "c06c36da-9adb-46eb-b4b7-a237f7062ea1",
       "rows": [
        [
         "COMMONAREA_MEDI",
         "214865",
         "69.9"
        ],
        [
         "COMMONAREA_AVG",
         "214865",
         "69.9"
        ],
        [
         "COMMONAREA_MODE",
         "214865",
         "69.9"
        ],
        [
         "NONLIVINGAPARTMENTS_MEDI",
         "213514",
         "69.4"
        ],
        [
         "NONLIVINGAPARTMENTS_MODE",
         "213514",
         "69.4"
        ],
        [
         "NONLIVINGAPARTMENTS_AVG",
         "213514",
         "69.4"
        ],
        [
         "FONDKAPREMONT_MODE",
         "210295",
         "68.4"
        ],
        [
         "LIVINGAPARTMENTS_MODE",
         "210199",
         "68.4"
        ],
        [
         "LIVINGAPARTMENTS_MEDI",
         "210199",
         "68.4"
        ],
        [
         "LIVINGAPARTMENTS_AVG",
         "210199",
         "68.4"
        ],
        [
         "FLOORSMIN_MODE",
         "208642",
         "67.8"
        ],
        [
         "FLOORSMIN_MEDI",
         "208642",
         "67.8"
        ],
        [
         "FLOORSMIN_AVG",
         "208642",
         "67.8"
        ],
        [
         "YEARS_BUILD_MODE",
         "204488",
         "66.5"
        ],
        [
         "YEARS_BUILD_MEDI",
         "204488",
         "66.5"
        ],
        [
         "YEARS_BUILD_AVG",
         "204488",
         "66.5"
        ],
        [
         "OWN_CAR_AGE",
         "202929",
         "66.0"
        ],
        [
         "LANDAREA_AVG",
         "182590",
         "59.4"
        ],
        [
         "LANDAREA_MEDI",
         "182590",
         "59.4"
        ],
        [
         "LANDAREA_MODE",
         "182590",
         "59.4"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COMMONAREA_MEDI</th>\n",
       "      <td>214865</td>\n",
       "      <td>69.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMMONAREA_AVG</th>\n",
       "      <td>214865</td>\n",
       "      <td>69.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMMONAREA_MODE</th>\n",
       "      <td>214865</td>\n",
       "      <td>69.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NONLIVINGAPARTMENTS_MEDI</th>\n",
       "      <td>213514</td>\n",
       "      <td>69.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NONLIVINGAPARTMENTS_MODE</th>\n",
       "      <td>213514</td>\n",
       "      <td>69.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NONLIVINGAPARTMENTS_AVG</th>\n",
       "      <td>213514</td>\n",
       "      <td>69.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FONDKAPREMONT_MODE</th>\n",
       "      <td>210295</td>\n",
       "      <td>68.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIVINGAPARTMENTS_MODE</th>\n",
       "      <td>210199</td>\n",
       "      <td>68.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIVINGAPARTMENTS_MEDI</th>\n",
       "      <td>210199</td>\n",
       "      <td>68.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIVINGAPARTMENTS_AVG</th>\n",
       "      <td>210199</td>\n",
       "      <td>68.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOORSMIN_MODE</th>\n",
       "      <td>208642</td>\n",
       "      <td>67.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOORSMIN_MEDI</th>\n",
       "      <td>208642</td>\n",
       "      <td>67.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOORSMIN_AVG</th>\n",
       "      <td>208642</td>\n",
       "      <td>67.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEARS_BUILD_MODE</th>\n",
       "      <td>204488</td>\n",
       "      <td>66.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEARS_BUILD_MEDI</th>\n",
       "      <td>204488</td>\n",
       "      <td>66.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEARS_BUILD_AVG</th>\n",
       "      <td>204488</td>\n",
       "      <td>66.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWN_CAR_AGE</th>\n",
       "      <td>202929</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LANDAREA_AVG</th>\n",
       "      <td>182590</td>\n",
       "      <td>59.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LANDAREA_MEDI</th>\n",
       "      <td>182590</td>\n",
       "      <td>59.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LANDAREA_MODE</th>\n",
       "      <td>182590</td>\n",
       "      <td>59.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Missing Values  % of Total Values\n",
       "COMMONAREA_MEDI                   214865               69.9\n",
       "COMMONAREA_AVG                    214865               69.9\n",
       "COMMONAREA_MODE                   214865               69.9\n",
       "NONLIVINGAPARTMENTS_MEDI          213514               69.4\n",
       "NONLIVINGAPARTMENTS_MODE          213514               69.4\n",
       "NONLIVINGAPARTMENTS_AVG           213514               69.4\n",
       "FONDKAPREMONT_MODE                210295               68.4\n",
       "LIVINGAPARTMENTS_MODE             210199               68.4\n",
       "LIVINGAPARTMENTS_MEDI             210199               68.4\n",
       "LIVINGAPARTMENTS_AVG              210199               68.4\n",
       "FLOORSMIN_MODE                    208642               67.8\n",
       "FLOORSMIN_MEDI                    208642               67.8\n",
       "FLOORSMIN_AVG                     208642               67.8\n",
       "YEARS_BUILD_MODE                  204488               66.5\n",
       "YEARS_BUILD_MEDI                  204488               66.5\n",
       "YEARS_BUILD_AVG                   204488               66.5\n",
       "OWN_CAR_AGE                       202929               66.0\n",
       "LANDAREA_AVG                      182590               59.4\n",
       "LANDAREA_MEDI                     182590               59.4\n",
       "LANDAREA_MODE                     182590               59.4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to calculate missing values by column# Funct \n",
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns\n",
    "\n",
    "# Missing values statistics\n",
    "missing_values = missing_values_table(train)\n",
    "missing_values.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8025857",
   "metadata": {},
   "source": [
    "There are a lot with missing values. The models I am training can handle missing values natively, but many make a boolean missing indicator feature like so: \n",
    "```python\n",
    "df['COMMONAREA_MEDI_missing'] = df['COMMONAREA_MEDI'].isnull().astype(int)\n",
    "df['COMMONAREA_MEDI'] = df['COMMONAREA_MEDI'].fillna(-1)\n",
    "\n",
    "# Imputation is also a technique that can be used. Like so: \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Make sure to drop the ids and target\n",
    "train = train.drop(columns = ['SK_ID_CURR', 'TARGET'])\n",
    "test = test.drop(columns = ['SK_ID_CURR'])\n",
    "```\n",
    "\n",
    "There are many forms of imputation but this is one form with PCA: \n",
    "```python\n",
    "# Make a pipeline with imputation and pca\n",
    "pipeline = Pipeline(steps = [('imputer', Imputer(strategy = 'median')),\n",
    "             ('pca', PCA())])\n",
    "\n",
    "# Fit and transform on the training data\n",
    "train_pca = pipeline.fit_transform(train)\n",
    "\n",
    "# transform the testing data\n",
    "test_pca = pipeline.transform(test)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b2bace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Fix DAYS_EMPLOYED anomaly\n",
    "train['DAYS_EMPLOYED_ANOM'] = (train['DAYS_EMPLOYED'] == 365243).astype(int)\n",
    "test['DAYS_EMPLOYED_ANOM']  = (test['DAYS_EMPLOYED'] == 365243).astype(int)\n",
    "\n",
    "train['DAYS_EMPLOYED'] = train['DAYS_EMPLOYED'].replace({365243: np.nan})\n",
    "test['DAYS_EMPLOYED']  = test['DAYS_EMPLOYED'].replace({365243: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35e86111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Drop the same columns from train & test BEFORE encoding\n",
    "cols_to_drop = [\n",
    "    \"SK_ID_CURR\", \"OWN_CAR_AGE\", \"DAYS_EMPLOYED\",\n",
    "    \"WEEKDAY_APPR_PROCESS_START\", \"HOUR_APPR_PROCESS_START\",\n",
    "    \"WALLSMATERIAL_MODE\", \"N\"\n",
    "]\n",
    "\n",
    "train.drop(columns=cols_to_drop, errors=\"ignore\", inplace=True)\n",
    "test.drop(columns=cols_to_drop, errors=\"ignore\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643ae81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (307511, 116)\n",
      "Testing shape: (48744, 116)\n",
      "Binary categorical columns: ['NAME_CONTRACT_TYPE', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'EMERGENCYSTATE_MODE']\n",
      "Multi-class categorical columns: ['CODE_GENDER', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE', 'ORGANIZATION_TYPE', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE']\n",
      "Final encoded training shape: (307511, 228)\n",
      "Final encoded testing shape: (48744, 228)\n"
     ]
    }
   ],
   "source": [
    "# 4. Split target\n",
    "y = train[\"TARGET\"]\n",
    "train_X = train.drop(columns=[\"TARGET\"])\n",
    "\n",
    "# 5. Align train and test *before* encoding\n",
    "train_X, test_X = train_X.align(test, join='inner', axis=1)\n",
    "\n",
    "print(\"Training shape:\", train_X.shape)\n",
    "print(\"Testing shape:\", test_X.shape)\n",
    "\n",
    "# 6. Identify categorical columns (only those that exist)\n",
    "one_hot_cols = [\n",
    "    'NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY',\n",
    "    'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
    "    'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE',\n",
    "    'ORGANIZATION_TYPE', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE',\n",
    "    'EMERGENCYSTATE_MODE'\n",
    "]\n",
    "\n",
    "# Keep only existing cols after align\n",
    "one_hot_cols = [c for c in one_hot_cols if c in train_X.columns]\n",
    "\n",
    "# Split by cardinality\n",
    "binary_cats = []\n",
    "multi_cats  = []\n",
    "\n",
    "for col in one_hot_cols:\n",
    "    unique_vals = train_X[col].dropna().unique()\n",
    "    if len(unique_vals) <= 2:\n",
    "        binary_cats.append(col)\n",
    "    else:\n",
    "        multi_cats.append(col)\n",
    "\n",
    "print(\"Binary categorical columns:\", binary_cats)\n",
    "print(\"Multi-class categorical columns:\", multi_cats)\n",
    "\n",
    "# 7. Build ColumnTransformer\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"binary\", OrdinalEncoder(), binary_cats),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown='ignore', sparse_output=False), multi_cats),\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "# 8. Fit on train_X, transform both train_X and test_X\n",
    "X_enc = ct.fit_transform(train_X)\n",
    "X_test_enc = ct.transform(test_X)\n",
    "\n",
    "# 9. Extract final feature names\n",
    "feature_names = ct.get_feature_names_out()\n",
    "print(\"Final encoded training shape:\", X_enc.shape)\n",
    "print(\"Final encoded testing shape:\", X_test_enc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d1a6653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, roc_auc_score\n",
    ")\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "def scores(y_true, y_pred, y_pred_proba):\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "    print(\"F1:\", f1_score(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"ROC-AUC:\", roc_auc_score(y_true, y_pred_proba))\n",
    "\n",
    "# logreg = LogisticRegression(\n",
    "#     penalty=\"l1\",\n",
    "#     solver=\"liblinear\",\n",
    "#     class_weight=\"balanced\",\n",
    "#     max_iter=200\n",
    "# )\n",
    "\n",
    "# # CV predictions\n",
    "# y_pred = cross_val_predict(logreg, X_enc, y, cv=5, method=\"predict\")\n",
    "# y_pred_proba = cross_val_predict(logreg, X_enc, y, cv=5, method=\"predict_proba\")[:, 1]\n",
    "\n",
    "# print(\"\\nLogistic Regression CV Scores\")\n",
    "# scores(y, y_pred, y_pred_proba)\n",
    "\n",
    "# # Fit final model\n",
    "# logreg.fit(X_enc, y)\n",
    "\n",
    "# # Predict on test set\n",
    "# logreg_test_pred = logreg.predict_proba(X_test_enc)[:, 1]\n",
    "\n",
    "# # Feature importance\n",
    "# coef_importance = pd.Series(\n",
    "#     abs(logreg.coef_[0]),\n",
    "#     index=feature_names\n",
    "# ).sort_values(ascending=False)\n",
    "\n",
    "# print(\"\\nTop 20 Logistic Regression Features:\")\n",
    "# print(coef_importance.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d597165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226148\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041738 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11113\n",
      "[LightGBM] [Info] Number of data points in the train set: 246008, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041002 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11201\n",
      "[LightGBM] [Info] Number of data points in the train set: 246009, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.041242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11111\n",
      "[LightGBM] [Info] Number of data points in the train set: 246009, number of used features: 219\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.047784 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11125\n",
      "[LightGBM] [Info] Number of data points in the train set: 246009, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.040633 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11096\n",
      "[LightGBM] [Info] Number of data points in the train set: 246009, number of used features: 218\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226148\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.042106 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11113\n",
      "[LightGBM] [Info] Number of data points in the train set: 246008, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039714 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11201\n",
      "[LightGBM] [Info] Number of data points in the train set: 246009, number of used features: 216\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045153 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11111\n",
      "[LightGBM] [Info] Number of data points in the train set: 246009, number of used features: 219\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.039427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11125\n",
      "[LightGBM] [Info] Number of data points in the train set: 246009, number of used features: 217\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 19860, number of negative: 226149\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033917 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11096\n",
      "[LightGBM] [Info] Number of data points in the train set: 246009, number of used features: 218\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=-0.000000\n",
      "[LightGBM] [Info] Start training from score -0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM CV Scores\n",
      "Accuracy: 0.7150280802963146\n",
      "Precision: 0.17154242801409908\n",
      "Recall: 0.6606646525679758\n",
      "F1: 0.2723649467758274\n",
      "Confusion Matrix:\n",
      " [[203478  79208]\n",
      " [  8424  16401]]\n",
      "ROC-AUC: 0.7579055977039819\n",
      "[LightGBM] [Info] Number of positive: 24825, number of negative: 282686\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.050427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 11117\n",
      "[LightGBM] [Info] Number of data points in the train set: 307511, number of used features: 219\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Start training from score 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 LightGBM Features:\n",
      "remainder__EXT_SOURCE_1                  1698\n",
      "remainder__EXT_SOURCE_3                  1695\n",
      "remainder__EXT_SOURCE_2                  1339\n",
      "remainder__DAYS_BIRTH                    1307\n",
      "remainder__AMT_CREDIT                    1241\n",
      "remainder__AMT_ANNUITY                   1145\n",
      "remainder__AMT_GOODS_PRICE               1078\n",
      "remainder__DAYS_ID_PUBLISH                914\n",
      "remainder__DAYS_LAST_PHONE_CHANGE         775\n",
      "remainder__DAYS_REGISTRATION              742\n",
      "remainder__AMT_INCOME_TOTAL               545\n",
      "remainder__REGION_POPULATION_RELATIVE     446\n",
      "remainder__AMT_REQ_CREDIT_BUREAU_YEAR     331\n",
      "remainder__TOTALAREA_MODE                 253\n",
      "onehot__CODE_GENDER_F                     234\n",
      "binary__FLAG_OWN_CAR                      222\n",
      "remainder__AMT_REQ_CREDIT_BUREAU_QRT      221\n",
      "remainder__LANDAREA_AVG                   208\n",
      "remainder__APARTMENTS_MODE                207\n",
      "binary__NAME_CONTRACT_TYPE                198\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# LightGBM Model\n",
    "lgbm = LGBMClassifier(\n",
    "    objective=\"binary\",\n",
    "    metric=\"auc\",\n",
    "    boosting_type=\"gbdt\",\n",
    "    n_estimators=800,\n",
    "    learning_rate=0.02,\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Cross-validated predictions (5-fold)\n",
    "lgb_pred = cross_val_predict(\n",
    "    lgbm, X_enc, y,\n",
    "    cv=5,\n",
    "    method=\"predict\"\n",
    ")\n",
    "\n",
    "lgb_pred_proba = cross_val_predict(\n",
    "    lgbm, X_enc, y,\n",
    "    cv=5,\n",
    "    method=\"predict_proba\"\n",
    ")[:, 1]\n",
    "\n",
    "print(\"\\nLightGBM CV Scores\")\n",
    "scores(y, lgb_pred, lgb_pred_proba)\n",
    "\n",
    "# Fit final model on ALL training data\n",
    "lgbm.fit(X_enc, y)\n",
    "\n",
    "# # Predict on real test data\n",
    "lgbm_test_pred = lgbm.predict_proba(X_test_enc)[:, 1]\n",
    "\n",
    "# Feature importance\n",
    "lgb_importance = pd.Series(\n",
    "    lgbm.feature_importances_,\n",
    "    index=feature_names\n",
    ").sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nTop 20 LightGBM Features:\")\n",
    "print(lgb_importance.head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
