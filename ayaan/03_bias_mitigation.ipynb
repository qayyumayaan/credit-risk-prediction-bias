{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99abf03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41e4565a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SK_ID_CURR', 'TARGET', 'NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OWN_CAR_AGE', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE', 'CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'ORGANIZATION_TYPE', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE', 'TOTALAREA_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']\n",
      "['SK_ID_CURR', 'NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OWN_CAR_AGE', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE', 'CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'ORGANIZATION_TYPE', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE', 'TOTALAREA_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load train & test\n",
    "train = pd.read_csv('../data/application_train.csv')\n",
    "test  = pd.read_csv('../data/application_test.csv')\n",
    "\n",
    "print(train.columns.tolist())\n",
    "print(test.columns.tolist())\n",
    "\n",
    "# Direct protected class features: \n",
    "['CODE_GENDER', 'DAYS_BIRTH', 'DAYS_EMPLOYED']\n",
    "\n",
    "# Indirect proxies: \n",
    "['OWN_CAR_AGE','CNT_CHILDREN']\n",
    "\n",
    "# Suspicious:\n",
    "['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea36a22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 122 columns.\n",
      "There are 67 columns that have missing values.\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Missing Values",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "% of Total Values",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "0e6db672-b3b0-4d73-a260-6d2fb8afef89",
       "rows": [
        [
         "COMMONAREA_MEDI",
         "214865",
         "69.9"
        ],
        [
         "COMMONAREA_AVG",
         "214865",
         "69.9"
        ],
        [
         "COMMONAREA_MODE",
         "214865",
         "69.9"
        ],
        [
         "NONLIVINGAPARTMENTS_MEDI",
         "213514",
         "69.4"
        ],
        [
         "NONLIVINGAPARTMENTS_MODE",
         "213514",
         "69.4"
        ],
        [
         "NONLIVINGAPARTMENTS_AVG",
         "213514",
         "69.4"
        ],
        [
         "FONDKAPREMONT_MODE",
         "210295",
         "68.4"
        ],
        [
         "LIVINGAPARTMENTS_MODE",
         "210199",
         "68.4"
        ],
        [
         "LIVINGAPARTMENTS_MEDI",
         "210199",
         "68.4"
        ],
        [
         "LIVINGAPARTMENTS_AVG",
         "210199",
         "68.4"
        ],
        [
         "FLOORSMIN_MODE",
         "208642",
         "67.8"
        ],
        [
         "FLOORSMIN_MEDI",
         "208642",
         "67.8"
        ],
        [
         "FLOORSMIN_AVG",
         "208642",
         "67.8"
        ],
        [
         "YEARS_BUILD_MODE",
         "204488",
         "66.5"
        ],
        [
         "YEARS_BUILD_MEDI",
         "204488",
         "66.5"
        ],
        [
         "YEARS_BUILD_AVG",
         "204488",
         "66.5"
        ],
        [
         "OWN_CAR_AGE",
         "202929",
         "66.0"
        ],
        [
         "LANDAREA_AVG",
         "182590",
         "59.4"
        ],
        [
         "LANDAREA_MEDI",
         "182590",
         "59.4"
        ],
        [
         "LANDAREA_MODE",
         "182590",
         "59.4"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>% of Total Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COMMONAREA_MEDI</th>\n",
       "      <td>214865</td>\n",
       "      <td>69.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMMONAREA_AVG</th>\n",
       "      <td>214865</td>\n",
       "      <td>69.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COMMONAREA_MODE</th>\n",
       "      <td>214865</td>\n",
       "      <td>69.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NONLIVINGAPARTMENTS_MEDI</th>\n",
       "      <td>213514</td>\n",
       "      <td>69.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NONLIVINGAPARTMENTS_MODE</th>\n",
       "      <td>213514</td>\n",
       "      <td>69.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NONLIVINGAPARTMENTS_AVG</th>\n",
       "      <td>213514</td>\n",
       "      <td>69.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FONDKAPREMONT_MODE</th>\n",
       "      <td>210295</td>\n",
       "      <td>68.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIVINGAPARTMENTS_MODE</th>\n",
       "      <td>210199</td>\n",
       "      <td>68.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIVINGAPARTMENTS_MEDI</th>\n",
       "      <td>210199</td>\n",
       "      <td>68.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LIVINGAPARTMENTS_AVG</th>\n",
       "      <td>210199</td>\n",
       "      <td>68.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOORSMIN_MODE</th>\n",
       "      <td>208642</td>\n",
       "      <td>67.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOORSMIN_MEDI</th>\n",
       "      <td>208642</td>\n",
       "      <td>67.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLOORSMIN_AVG</th>\n",
       "      <td>208642</td>\n",
       "      <td>67.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEARS_BUILD_MODE</th>\n",
       "      <td>204488</td>\n",
       "      <td>66.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEARS_BUILD_MEDI</th>\n",
       "      <td>204488</td>\n",
       "      <td>66.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>YEARS_BUILD_AVG</th>\n",
       "      <td>204488</td>\n",
       "      <td>66.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWN_CAR_AGE</th>\n",
       "      <td>202929</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LANDAREA_AVG</th>\n",
       "      <td>182590</td>\n",
       "      <td>59.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LANDAREA_MEDI</th>\n",
       "      <td>182590</td>\n",
       "      <td>59.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LANDAREA_MODE</th>\n",
       "      <td>182590</td>\n",
       "      <td>59.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Missing Values  % of Total Values\n",
       "COMMONAREA_MEDI                   214865               69.9\n",
       "COMMONAREA_AVG                    214865               69.9\n",
       "COMMONAREA_MODE                   214865               69.9\n",
       "NONLIVINGAPARTMENTS_MEDI          213514               69.4\n",
       "NONLIVINGAPARTMENTS_MODE          213514               69.4\n",
       "NONLIVINGAPARTMENTS_AVG           213514               69.4\n",
       "FONDKAPREMONT_MODE                210295               68.4\n",
       "LIVINGAPARTMENTS_MODE             210199               68.4\n",
       "LIVINGAPARTMENTS_MEDI             210199               68.4\n",
       "LIVINGAPARTMENTS_AVG              210199               68.4\n",
       "FLOORSMIN_MODE                    208642               67.8\n",
       "FLOORSMIN_MEDI                    208642               67.8\n",
       "FLOORSMIN_AVG                     208642               67.8\n",
       "YEARS_BUILD_MODE                  204488               66.5\n",
       "YEARS_BUILD_MEDI                  204488               66.5\n",
       "YEARS_BUILD_AVG                   204488               66.5\n",
       "OWN_CAR_AGE                       202929               66.0\n",
       "LANDAREA_AVG                      182590               59.4\n",
       "LANDAREA_MEDI                     182590               59.4\n",
       "LANDAREA_MODE                     182590               59.4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to calculate missing values by column# Funct \n",
    "def missing_values_table(df):\n",
    "        # Total missing values\n",
    "        mis_val = df.isnull().sum()\n",
    "        \n",
    "        # Percentage of missing values\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        \n",
    "        # Make a table with the results\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        \n",
    "        # Rename the columns\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        \n",
    "        # Sort the table by percentage of missing descending\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        \n",
    "        # Print some summary information\n",
    "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        \n",
    "        # Return the dataframe with missing information\n",
    "        return mis_val_table_ren_columns\n",
    "\n",
    "# Missing values statistics\n",
    "missing_values = missing_values_table(train)\n",
    "missing_values.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b2bace6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Fix DAYS_EMPLOYED anomaly\n",
    "train['DAYS_EMPLOYED_ANOM'] = (train['DAYS_EMPLOYED'] == 365243).astype(int)\n",
    "test['DAYS_EMPLOYED_ANOM']  = (test['DAYS_EMPLOYED'] == 365243).astype(int)\n",
    "\n",
    "train['DAYS_EMPLOYED'] = train['DAYS_EMPLOYED'].replace({365243: np.nan})\n",
    "test['DAYS_EMPLOYED']  = test['DAYS_EMPLOYED'].replace({365243: np.nan})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e86111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Drop the same columns from train & test BEFORE encoding\n",
    "cols_to_drop = [\n",
    "    \"SK_ID_CURR\", \"OWN_CAR_AGE\",\n",
    "    \"WEEKDAY_APPR_PROCESS_START\", \"HOUR_APPR_PROCESS_START\",\n",
    "    \"WALLSMATERIAL_MODE\", \"N\"\n",
    "]\n",
    "\n",
    "biased_cols = ['CODE_GENDER', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'OWN_CAR_AGE','CNT_CHILDREN']\n",
    "\n",
    "train.drop(columns=cols_to_drop, errors=\"ignore\", inplace=True)\n",
    "test.drop(columns=cols_to_drop, errors=\"ignore\", inplace=True)\n",
    "\n",
    "train_unbiased = train\n",
    "test_unbiased = test\n",
    "train_unbiased.drop(columns=biased_cols, errors=\"ignore\", inplace=True)\n",
    "test_unbiased.drop(columns=biased_cols, errors=\"ignore\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643ae81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_encode(train_df, test_df, target_col=\"TARGET\"):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "        X_enc, X_test_enc, y, feature_names, ct\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "    # 1. Split target\n",
    "    y = train_df[target_col]\n",
    "    train_X = train_df.drop(columns=[target_col])\n",
    "\n",
    "    # 2. Align train/test\n",
    "    train_X, test_X = train_X.align(test_df, join=\"inner\", axis=1)\n",
    "\n",
    "    # 3. Identify categorical columns\n",
    "    one_hot_cols = [\n",
    "        'NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY',\n",
    "        'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
    "        'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'OCCUPATION_TYPE',\n",
    "        'ORGANIZATION_TYPE', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE',\n",
    "        'EMERGENCYSTATE_MODE'\n",
    "    ]\n",
    "\n",
    "    # Keep only those present\n",
    "    one_hot_cols = [c for c in one_hot_cols if c in train_X.columns]\n",
    "\n",
    "    # 4. Split binary vs multi\n",
    "    binary_cats = []\n",
    "    multi_cats = []\n",
    "\n",
    "    for col in one_hot_cols:\n",
    "        unique_vals = train_X[col].dropna().unique()\n",
    "        if len(unique_vals) <= 2:\n",
    "            binary_cats.append(col)\n",
    "        else:\n",
    "            multi_cats.append(col)\n",
    "\n",
    "    # 5. Build ColumnTransformer\n",
    "    ct = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"binary\", OrdinalEncoder(), binary_cats),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown='ignore', sparse_output=False), multi_cats),\n",
    "        ],\n",
    "        remainder=\"passthrough\"\n",
    "    )\n",
    "\n",
    "    # 6. Fit/transform\n",
    "    X_enc = ct.fit_transform(train_X)\n",
    "    X_test_enc = ct.transform(test_X)\n",
    "\n",
    "    feature_names = ct.get_feature_names_out()\n",
    "\n",
    "    return X_enc, X_test_enc, y, feature_names, ct\n",
    "\n",
    "def make_numeric_for_corr(df):\n",
    "    df_corr = df.copy()\n",
    "    for col in df_corr.columns:\n",
    "        if df_corr[col].dtype == 'object' or str(df_corr[col].dtype).startswith('category'):\n",
    "            df_corr[col] = df_corr[col].astype('category').cat.codes\n",
    "    return df_corr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f56e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Cash loans'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m train_unbiased \u001b[38;5;241m=\u001b[39m train\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     11\u001b[0m test_unbiased \u001b[38;5;241m=\u001b[39m test\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m---> 13\u001b[0m corr \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_unbiased\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m corr[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCODE_GENDER\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msort_values(ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[:\u001b[38;5;241m10\u001b[39m]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# train_unbiased.drop(columns=biased_cols, errors=\"ignore\", inplace=True)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# test_unbiased.drop(columns=biased_cols, errors=\"ignore\", inplace=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/pandas/core/frame.py:11076\u001b[0m, in \u001b[0;36mDataFrame.corr\u001b[0;34m(self, method, min_periods, numeric_only)\u001b[0m\n\u001b[1;32m  11074\u001b[0m cols \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m  11075\u001b[0m idx \u001b[38;5;241m=\u001b[39m cols\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m> 11076\u001b[0m mat \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m  11078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpearson\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m  11079\u001b[0m     correl \u001b[38;5;241m=\u001b[39m libalgos\u001b[38;5;241m.\u001b[39mnancorr(mat, minp\u001b[38;5;241m=\u001b[39mmin_periods)\n",
      "File \u001b[0;32m~/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/pandas/core/frame.py:2002\u001b[0m, in \u001b[0;36mDataFrame.to_numpy\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2001\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(dtype)\n\u001b[0;32m-> 2002\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dtype:\n\u001b[1;32m   2004\u001b[0m     result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(result, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "File \u001b[0;32m~/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/pandas/core/internals/managers.py:1713\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[0;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[1;32m   1711\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1712\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1713\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1714\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[1;32m   1715\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[1;32m   1717\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[0;32m~/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/pandas/core/internals/managers.py:1772\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[0;34m(self, dtype, na_value)\u001b[0m\n\u001b[1;32m   1770\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1771\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[0;32m-> 1772\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   1773\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Cash loans'"
     ]
    }
   ],
   "source": [
    "# Prepare biased versions (original)\n",
    "train_biased = train.copy()\n",
    "test_biased = test.copy()\n",
    "\n",
    "biased_cols = ['CODE_GENDER', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'OWN_CAR_AGE', 'CNT_CHILDREN']\n",
    "\n",
    "# Prepare unbiased versions\n",
    "train_unbiased = train.copy()\n",
    "test_unbiased = test.copy()\n",
    "\n",
    "train_corr = make_numeric_for_corr(train_unbiased)\n",
    "\n",
    "corr = train_corr.corr()\n",
    "corr['CODE_GENDER'].sort_values(ascending=False)[:10]\n",
    "cutoff = 0.05\n",
    "\n",
    "proxy_features = set()\n",
    "\n",
    "for bcol in biased_cols:\n",
    "    if bcol in corr.columns:\n",
    "        high_corr = corr.index[(corr[bcol].abs() > cutoff)]\n",
    "        proxy_features.update(high_corr.tolist())\n",
    "\n",
    "# train_unbiased.drop(columns=biased_cols, errors=\"ignore\", inplace=True)\n",
    "# test_unbiased.drop(columns=biased_cols, errors=\"ignore\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db463a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biased train shape: (307511, 229)\n",
      "Biased test shape: (48744, 229)\n",
      "Unbiased train shape: (307511, 223)\n",
      "Unbiased test shape: (48744, 223)\n"
     ]
    }
   ],
   "source": [
    "# Run biased pipeline\n",
    "X_biased, X_test_biased, y_biased, feature_names_biased, ct_biased = \\\n",
    "    preprocess_and_encode(train_biased, test_biased)\n",
    "\n",
    "print(\"Biased train shape:\", X_biased.shape)\n",
    "print(\"Biased test shape:\", X_test_biased.shape)\n",
    "\n",
    "# Run unbiased pipeline\n",
    "X_unbiased, X_test_unbiased, y_unbiased, feature_names_unbiased, ct_unbiased = \\\n",
    "    preprocess_and_encode(train_unbiased, test_unbiased)\n",
    "\n",
    "print(\"Unbiased train shape:\", X_unbiased.shape)\n",
    "print(\"Unbiased test shape:\", X_test_unbiased.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1a6653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, confusion_matrix, roc_auc_score\n",
    ")\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "def scores(y_true, y_pred, y_pred_proba):\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred))\n",
    "    print(\"F1:\", f1_score(y_true, y_pred))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "    print(\"ROC-AUC:\", roc_auc_score(y_true, y_pred_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd82aa1f",
   "metadata": {},
   "source": [
    "What I will eventually do is quantify how much the feature input weights in the model that has more features has on the output by directly comparing the two models. I will then need a vector which quantifies and tells the BIASED model how to adjust the weight of the input features to be unbiased, and the same for the inverse task (make an unbiased model biased). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9431a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_enc = ct.fit_transform(train_X)\n",
    "X_test_enc = ct.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d597165",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LightGBM CV Scores\n",
      "Accuracy: 0.7156296847917636\n",
      "Precision: 0.17197812558928907\n",
      "Recall: 0.6612688821752266\n",
      "F1: 0.2729653555483501\n",
      "Confusion Matrix:\n",
      " [[203648  79038]\n",
      " [  8409  16416]]\n",
      "ROC-AUC: 0.7585581891633574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/qayyuma/Documents/GitHub/credit-risk-prediction-bias/.venv/lib/python3.10/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 20 LightGBM Features:\n",
      "remainder__EXT_SOURCE_1                  1706\n",
      "remainder__EXT_SOURCE_3                  1688\n",
      "remainder__EXT_SOURCE_2                  1278\n",
      "remainder__AMT_CREDIT                    1211\n",
      "remainder__DAYS_BIRTH                    1129\n",
      "remainder__DAYS_EMPLOYED                 1105\n",
      "remainder__AMT_ANNUITY                   1056\n",
      "remainder__AMT_GOODS_PRICE               1005\n",
      "remainder__DAYS_ID_PUBLISH                846\n",
      "remainder__DAYS_LAST_PHONE_CHANGE         808\n",
      "remainder__DAYS_REGISTRATION              711\n",
      "remainder__AMT_INCOME_TOTAL               539\n",
      "remainder__REGION_POPULATION_RELATIVE     474\n",
      "remainder__AMT_REQ_CREDIT_BUREAU_YEAR     317\n",
      "remainder__TOTALAREA_MODE                 272\n",
      "remainder__AMT_REQ_CREDIT_BUREAU_QRT      234\n",
      "remainder__LANDAREA_AVG                   211\n",
      "remainder__APARTMENTS_MODE                210\n",
      "binary__FLAG_OWN_CAR                      204\n",
      "binary__NAME_CONTRACT_TYPE                198\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# LightGBM Model\n",
    "lgbm = LGBMClassifier(\n",
    "    objective=\"binary\",\n",
    "    metric=\"auc\",\n",
    "    boosting_type=\"gbdt\",\n",
    "    n_estimators=800,\n",
    "    learning_rate=0.02,\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42,\n",
    "    verbose=-1,\n",
    ")\n",
    "\n",
    "# Cross-validated predictions (5-fold)\n",
    "lgb_pred = cross_val_predict(lgbm, X_enc, y, cv=5, method=\"predict\")\n",
    "\n",
    "lgb_pred_proba = cross_val_predict(lgbm, X_enc, y, cv=5, method=\"predict_proba\")[:, 1]\n",
    "\n",
    "print(\"\\nLightGBM CV Scores\")\n",
    "scores(y, lgb_pred, lgb_pred_proba)\n",
    "\n",
    "# Fit final model on ALL training data\n",
    "lgbm.fit(X_enc, y)\n",
    "\n",
    "# # Predict on real test data\n",
    "lgbm_test_pred = lgbm.predict_proba(X_test_enc)[:, 1]\n",
    "\n",
    "# Feature importance\n",
    "lgb_importance = pd.Series(lgbm.feature_importances_, index=feature_names).sort_values(\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "print(\"\\nTop 20 LightGBM Features:\")\n",
    "print(lgb_importance.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
